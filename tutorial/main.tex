\documentclass[dvipdfmx,11pt]{beamer}		% for my notebook computer and my Mac computer
%\documentclass[11pt]{beamer}			% for overleaf

\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{amsthm}
\usepackage{multicol}
\usepackage{listings}
\usepackage{otf}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{mathtools}

\usetheme{Berlin}	%全体のデザイン

\useoutertheme[subsection=false]{smoothbars}	%デザインのカスタマイズ

\setbeamertemplate{navigation symbols}{}	%右下のちっちゃいナビゲーション記号を非表示

\AtBeginSubsection[]	%サブセクションごとに目次を表示
{\begin{frame}{Contents}
	\tableofcontents[currentsubsection]
\end{frame}}
\newtheorem{defi}{Definition}
\newtheorem{thm}[defi]{Theorem}
\newtheorem{prop}[defi]{Proposition}
\newtheorem{conj}[defi]{Conjecture}
\newtheorem{exam}[defi]{Example}
\newtheorem{prob}[defi]{Problem}
\newtheorem{set}[defi]{Setting}
\newtheorem{claim}[defi]{Claim}

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Hil}{\mathcal{H}}
\newcommand{\Loss}{\mathcal{L}_{D}}
\newcommand{\MLsp}{(\X, \Y, D, \Hil, \Loss)}

\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\title{Machine Learning tutorial}
\author{Takaya KOIZUMI}
\institute{Mathematical Science, B4}
\date{Applied Mathematics and Physics informal seminor}
\begin{document}
    \begin{frame}\frametitle{}
        \titlepage
    \end{frame}
    \section*{Contents}
    \begin{frame}\frametitle{Contents}
            \tableofcontents
    \end{frame}
    \section{機械学習の枠組み}
    \subsection{機械学習とは}
    \begin{frame}\frametitle{機械学習とは}
        機械学習とは, 「関数近似論」である.
        \begin{block}{世の中で機械学習を使って実現したと言われている技術}
            \begin{enumerate}
                \item 翻訳~~($\{$全ての日本語$\}$$\to$$\{$全ての英語$\}$という関数)
                \item メール分類~~($\{$全てのメールの文章$\}$$\to$$\{$迷惑メール, 非迷惑メール$\}$という関数)
                \item 音声認識~~($\{$音声$\}$$\to$$\{$文章$\}$という関数)
            \end{enumerate}
        \end{block}
        もちろん, 間違いを起こすこともある. (大事なメールが, 迷惑メールに入ることも...)
    \end{frame}
    \begin{frame}\frametitle{数学的には}
        前スライドの話を集合論を用いて, もう少し数学的にきちんと書くならば, 以下のようになるだろう.
        \begin{block}{機械学習?}
            $\X$, $\Y$をそれぞれ$\R^d$, $\R^m$の部分集合とする. 
            この時, 良い関数$f:\X\to\Y$を見つけることを機械学習という. 
        \end{block} 
        しかし, この定義には以下の問題がある.
        \begin{block}{上の定義の問題点}
            \begin{enumerate}
                \item 候補となる関数が多すぎる. (ヒントも何もないのに探せない)
                \item 良い関数とは何か, 定義されていない.
            \end{enumerate}
        \end{block}
    \end{frame}
    \subsection{機械学習の数学的定式化へ}
    \begin{frame}\frametitle{前半の問題解消}
        では, まず前半の「候補となる関数が多すぎる.」という問題を解決していこう. \\ \indent
        この問題の解決方法として, 人間がヒント(条件)を与えてあげることで, 関数全ての
        集合ではなく, ある程度絞った集合$\Hil$にするということを考える. この$\Hil$のことを仮設空間(Hyposesis space)と呼ぶ.
        \begin{defi}[仮設空間]
            $\X$, $\Y$をそれぞれ$\R^d$, $\R^m$の部分集合とする. この時, 集合
            \begin{equation*}
                \Hil :=\{f_{w} :\X\to\Y\mid\text{$f_{w}$に関する条件}\}
            \end{equation*}
            のことを仮設空間と呼び, $\X$を特徴量空間, $\Y$をラベル空間と呼ぶ. また, $f_w\in\Hil$を
            仮設と呼ぶ. 
        \end{defi}
    \end{frame}
    \begin{frame}\frametitle{後半の問題解消}
        では, 後半の「良い関数」というものを定義していこう. 
        機械学習において, 良い関数とは, 未知のデータ$X$に対して正しい値$Y$を返す関数である. 
        そのために, 関数$f$に対してその良さを表す指標である汎化誤差を定義する.
        \begin{defi}[汎化誤差, 損失関数]
            $\Hil$を仮設空間, $(\Omega, \mathcal{F}, \mathbb{P})$を確率空間, $\rho$をデータの確率分布とする.
            この時, 汎化誤差$\ell:\Hil\to\R$を, 
            \begin{equation*}
                \ell(f_{\theta}) = \mathbb{E}_{(X, Y)\sim\rho}[l(f_{w}(X), Y)]
            \end{equation*}
            と定義する. ここで, $l:\Y\times\Y\to\R$は損失関数と呼ばれる凸関数である. 
        \end{defi}
    \end{frame}
    \begin{frame}
        \frametitle{損失関数の具体例}
        \begin{block}{損失関数}
            ここで,　よく使われる損失関数の例をいくつか述べておく. 
            \begin{enumerate}
                \item 2乗損失関数 $l(y_1, y_2) = (y_1 - y_2)^2$
                \item 交差エントロピー誤差 $l(y_1, y_2) = -y_2\log y_1$
            \end{enumerate}
        \end{block}
        これで, 「良い関数」を作るためには, 汎化誤差$\ell$を最小化させるような仮設空間$\Hil$の元$f$を見つけば良いと言うことになったわけだが, 
        汎化誤差には期待値が含まれるため, 直接最適化させることが難しい. そのため, 持っているデータを利用して別の関数を用意し, その関数を
        最小化することを考える. 
    \end{frame}
    \begin{frame}
        \frametitle{データと経験損失関数}
        \begin{defi}[データ]
            $(\Omega, \mathcal{F}, \mathbb{P})$を確率空間, $\rho$をデータの確率分布とする.
            $\{(X_n, Y_n)\}_{n = 1}^{N}$を$\rho$に従う独立な確率変数列とした時, $\{(X_n, Y_n)\}_{n = 1}^{N}$の観測値$\{(X_n(\omega), Y_n(\omega))\}_{n = 1}^{N}$
            のことをデータ(Data)と呼び, $D = \{(x_n, y_n)\}_{n = 1}^{N}$と表記する.
        \end{defi}
        \begin{defi}[経験損失関数]
            $\Hil$を仮設空間, $D = \{(x_n, y_n)\}_{n = 1}^{N}$をデータ, $l:\Y\times\Y\to\R$を
            損失関数とする. この時, 経験損失関数$\Loss:\Hil\to\R$を,
            \begin{equation*}
                \Loss(f_{w}) = \sum_{n = 1}^{N}l(f_{\theta}(x_n), y_n)
            \end{equation*}
            と定義する. 
        \end{defi}
    \end{frame}
    \begin{frame}
        \frametitle{機械学習と学習アルゴリズム}
        さて, ここで改めて機械学習を定義しよう.
        \begin{defi}[機械学習, 学習アルゴリズム]
            $\Hil$を仮設空間, $D$をデータ, $\Loss$を経験損失関数とする. この時, 
            アルゴリズム$\mathcal{A}$を用いて, $\Loss$を最小化・最大化させる過程のことを機械学習
            (あるいは単に学習)と呼び, その時のアルゴリズム$\mathcal{A}$のことを学習アルゴリズムと呼ぶ. 
            また, 最適解$f^{*}\in\Hil$を最適仮設と呼び, その時のパラメータ$w^{*}$を最適パラメータと呼ぶ. 
        \end{defi}
        これ以降, 5つ組$(\X, \Y, D, \Hil, \Loss)$をML空間と呼ぶことにする. 
    \end{frame}
    \section{単回帰と重回帰}
    \subsection{単回帰分析}
    \begin{frame}\frametitle{最も基礎的なモデル}
        まず, 最も基礎的な機械学習モデルである単回帰分析を紹介する. 
        \begin{exam}[単回帰分析]
            ML空間$\MLsp$を以下で定義する. $\X = \R$, $\Y = \R$, 
            \begin{align*}
                \Hil &= \{f:\X\to\Y\mid f(x) = wx, w\in\R\},\\
                \Loss(f) &= \sum_{i = 1}^{N}(f(x_i) - y_i)^2.
            \end{align*}
            このML空間$\MLsp$上で,
            \begin{align*}
                \argmin_{f\in\Hil}\Loss(f)
            \end{align*}
            を求める問題を単回帰分析という.
        \end{exam}
    \end{frame}
    \begin{frame}
        \frametitle{SRAの学習}
        SRAは勾配降下法などを用いて解くこともできるが, 今回は解析的に最適パラメータを求める. 
        SRAの経験損失関数は$w$に関して2次関数となっているので, 平方完成を用いると, 
        \begin{equation*}
            f^{*}(x) = w^{*}x, \hspace{20pt} w^* = \frac{\sum_{i = 1}^{N}x_{i}y_{i}}{\sum_{i = 1}^{N}x_{i}^2}
        \end{equation*}
        と定義される$f^*\in\Hil$が最適であることがわかる. 
    \end{frame}
    \subsection{重回帰分析}
    \begin{frame}
        \frametitle{重回帰分析}
        \begin{exam}[重回帰分析]
            ML空間$\MLsp$を以下のように定義する.\\
            $\X = \R^d(N\geq d)$, $\Y = \R$, 
            \begin{align*}
                \Hil &= \{f:\X\to\Y\mid f(x) = W^{\top}x + b, W\in\R^{d}, b\in\R\},\\
                \Loss(f) &= \sum_{i = 1}^{N}(f(x_i) - y_i)^2.
            \end{align*}
            このML空間$\MLsp$上で
            \begin{align*}
                \argmin_{f\in\Hil}\Loss(f)
            \end{align*}
            を求める問題を重回帰分析という.
        \end{exam}
    \end{frame}
    \begin{frame}
        \frametitle{MRAの学習}
        SRAの時と同様に解析的に最適パラメータを求める(簡単のために$b = 0$とする). $X\in\R^{N\times d}$, $\mathbf{y}\in\R^N$を
        $X = [x_1 x_2 \ldots x_N]^{T}$, $\mathbf{y} = (y_{1}, y_{2}, \cdots, y_{N})^{\top}$と定義する. もし$X$が可逆であるとすると, 
        \begin{align*}
            f^{*}(x) = W_*^{\top}x, \hspace{20pt} W_* = (X^\top X)^{-1}X^\top\mathbf{y}
        \end{align*}
        と定義される$f^*\in\Hil$が最適であることがわかる. なお, $b\neq0$の場合も
        デザイン行列$X$を変更し, $w_{0} = b$とすることで, 上記の計算の場合に帰着することができる\cite{PFN}.
    \end{frame}
    \section{過学習と正則化}
    \subsection{多項式回帰}
    \begin{frame}
        \frametitle{基底関数}
        この節では, はじめに多項式回帰を紹介する. 
        その前に基底関数というものを導入する. 
        \begin{defi}[基底関数]
            $\X$を$\R$の部分集合とする. $\X$から$\X$への$C^1$級関数列$\{\phi_{n}\}_{n = 1}^{d}$が
            $\R$上1次独立である時, $\Phi(x) = (\phi_{0}(x), \phi_{1}(x), \ldots, \phi_{d}(x))$で定義される$\Phi:\X\to\R^{d + 1}$
            を基底関数と呼ぶ. 
        \end{defi}
        基底関数を用いることで, 非線形なデータにも対応することができる. 
    \end{frame}
    \begin{frame}\frametitle{多項式回帰}
        \begin{exam}[多項式回帰]
            ML空間$\MLsp$を以下のように定義する.\\
            $\X = \R, \Y = \R$, 
            \begin{align*}
                \Hil &= \{f:\X\to\Y\mid f(x) = W^{\top}\Phi(x), W\in\R^{d + 1}\},\\
                \Loss(f) &= \sum_{i = 1}^{N}(f(x_i) - y_i)^2.
            \end{align*}
            ここで, $\phi_{n}(x) = x^{n}$, $n\in\{0, 1, \cdots, d\}$とする.\\
            このML空間$\MLsp$上で
            \begin{align*}
                \argmin_{f\in\Hil}\Loss(f)
            \end{align*}
            を求める問題を多項式回帰という. 
        \end{exam}
    \end{frame}
    \begin{frame}
        \frametitle{多項式回帰での学習}
            今回も解析的に解くことにする. $X = [\Phi(x_1), \Phi(x_{2}), \cdots, \Phi(x_N)]^{T}\in\R^{N\times d}$とし, 
            $\mathbf{y} = (y_{1}, y_{2}, \cdots, y_{N})^{T}\in\R^{N}$とする. この時, 最適仮説$f^{*}$は
            重回帰分析と同様に$W = (X^\top X)^{-1}X^\top\mathbf{y}$とすれば
            \begin{align*}
                f^{*}(x) = W^{\top}x
            \end{align*}
            である. 
            \begin{block}{学習パラメータとハイパーパラメータ}
                多項式回帰の多項式の次数$d\in\N$や基底関数$\{\phi_{n}\}_{n = 1}^{d}$のように
                コンピュータに学習させるのではなく, 機械学習モデルの設計者が設定するパラメータのことを
                ハイパーパラメータと呼ぶ. 一方, $W\in\R^{d + 1}$のように, データからコンピュータが自動で学習
                するパラメータのことを学習パラメータと呼び, $\Theta$と表す.
            \end{block}
    \end{frame}
    \begin{frame}
        \frametitle{多項式回帰の過学習}
        \begin{columns}[t]
            \begin{column}{0.65\textwidth} 
                \begin{figure}
                    \centering
                    \includegraphics[width = 6.8cm]{Image/overfitting.png}
                    \caption{$d = 3$の時の多項式回帰}
              　\end{figure}
            \end{column}
            \begin{column}{0.75\textwidth}
                多項式回帰で学習を行うと左の図\\
                のように, 「教師データには適合し\\ているが, 未知のデータ
                には全く対\\応できない」モデルが学習されて\\しまう. \\
                \indent
                このように, 訓練誤差に対して, \\
                汎化誤差が大きくなってしまう\\
                ことを\textbf{過学習}と呼ぶ. 
            \end{column}
        \end{columns}
    \end{frame}
    \subsection{多項式回帰と正則化}
    \begin{frame}
        \frametitle{正則化}
        過学習を防ぐために, 学習パラメータを制限する方法のことを
        正則化(regularization)と呼ぶ. 具体的には経験損失関数に正則化項と
        いうものを加えて, パラメータが大きくなり過ぎないようにする. 
        \begin{defi}[正則化]
            $\Loss:\Hil\to\R$を経験損失関数とする. $\Loss^{R} := \Loss + L^{R}$とする.
            この時, $\Loss^{R}$を$\Loss$の正則化と呼び, $L^R:\Theta\to\R$を正則化項と呼ぶ.
        \end{defi}
    \end{frame}
    \begin{frame}
        \frametitle{Ridge正則化多項式回帰}
        \begin{exam}[Ridge正則化多項式回帰]
            $\lambda\in\R^{+}\coloneqq\{x\in\R\mid x\geq0\}$, $d\in\N$を任意にとる. 多項式回帰のML空間$\MLsp$の
            経験損失関数を
            \begin{align*}
                \Loss(f) &= \sum_{i = 1}^{N}(f(x_i) - y_i)^2 + \lambda W^\top W
            \end{align*}
            と正則化する. (ここで, $\lambda W^{\top}W$が正則化項である.) 
            このML空間$\MLsp$上で
            \begin{align*}
                \argmin_{f\in\Hil}\Loss(f)
            \end{align*}
            を求める問題をRidge正則化多項式回帰という. 
        \end{exam}
    \end{frame}
    \begin{frame}
        \frametitle{Ridge多項式回帰での学習}
            $X = [\Phi(x_1), \Phi(x_{2}), \cdots, \Phi(x_N)]^{T}\in\R^{N\times d}$とし, 
            $\mathbf{y} = (y_{1}, y_{2}, \cdots, y_{N})^{T}\in\R^{N}$とする. この時, 最適仮説$f^{*}$は
            \begin{align*}
                f^{*}(x) = W_*^{\top}x, \hspace{10pt} W_* = (X^\top X + \lambda I)^{-1}X^\top\mathbf{y}
            \end{align*}
            となる. (ここで, $I$は単位行列である. )
            % あとで計算する.  
    \end{frame}
    \begin{frame}
        \frametitle{正則化の実験}
        \begin{columns}[t]
            \begin{column}{0.65\textwidth} 
                \begin{figure}
                    \centering
                    \includegraphics[width = 6.8cm]{Image/regulared.png}
                    \caption{$d = 3$の時のRidge正則化多項式回帰}
              　\end{figure}
            \end{column}
            \begin{column}{0.75\textwidth}
                正則化を行うことで, データに完全\\
                にfitせず, 未知のデータにも\\
                ある程度対応できるようになった. \\
                ただ, -10以下のデータに関しては\\
                逆に精度が下がる結果になって\\
                しまった. (方程の方が綺麗...)
            \end{column}
        \end{columns}
    \end{frame}
    \section{References}
%
    \begin{frame}\frametitle{References}
	    \begin{thebibliography}{9}
	    \beamertemplatetextbibitems
		    \bibitem{PFN} Preferred Networks, ディープラーニング入門 Chainer チュートリアル,
            https://tutorials.chainer.org/ja/index.html, 2019
	    \end{thebibliography}
    \end{frame}
\end{document}


